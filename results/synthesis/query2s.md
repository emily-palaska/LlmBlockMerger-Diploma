# String Code Synthesis
Query `Create a regression model.`
## Script Variables
- RBF:<br>
>RBF is an acronym for Radial Basis Function. It is a kernel function that is used in
- PolynomialFeatures:<br>
>PolynomialFeatures is a class that takes in a dataset and transforms it into a new dataset with polynomial
- Nystroem:<br>
>Nystroem is a kernel-based method that is used to transform the input data into a high
- classifiers:<br>
>The variable classifiers are used to determine the number of classifiers to be used in the script. They are
- GaussianProcessClassifier:<br>
>The GaussianProcessClassifier is a machine learning classifier that uses Gaussian processes to make predictions. It is a
- LogisticRegression:<br>
>Logistic regression is a supervised machine learning algorithm that is used for classification problems. It is a type
- HistGradientBoostingClassifier:<br>
>HistGradientBoostingClassifier is a machine learning algorithm that uses a gradient boosting technique to fit a history
- KBinsDiscretizer:<br>
>KBinsDiscretizer is a class that is used to discretize continuous features into a fixed number
- make_pipeline:<br>
>It is a function that takes in a list of classifiers and returns a pipeline object. The pipeline object
- SplineTransformer:<br>
>SplineTransformer is a class that transforms the input data into a new representation using splines. It
## Synthesis Blocks
### notebooks/plot_classification_probability.ipynb
CONTEXT:  Probabilistic classifiers  We will plot the decision boundaries of several classifiers that have a `predict_proba` method. This will allow
us to visualize the uncertainty of the classifier in regions where it is not certain of its prediction.   COMMENT:
```python
classifiers = {
    "Logistic regression\n(C=0.01)": LogisticRegression(C=0.1),
    "Logistic regression\n(C=1)": LogisticRegression(C=100),
    "Gaussian Process": GaussianProcessClassifier(kernel=1.0 * RBF([1.0, 1.0])),
    "Logistic regression\n(RBF features)": make_pipeline(
        Nystroem(kernel="rbf", gamma=5e-1, n_components=50, random_state=1),
        LogisticRegression(C=10),
    ),
    "Gradient Boosting": HistGradientBoostingClassifier(),
    "Logistic regression\n(binned features)": make_pipeline(
        KBinsDiscretizer(n_bins=5, quantile_method="averaged_inverted_cdf"),
        PolynomialFeatures(interaction_only=True),
        LogisticRegression(C=10),
    ),
    "Logistic regression\n(spline features)": make_pipeline(
        SplineTransformer(n_knots=5),
        PolynomialFeatures(interaction_only=True),
        LogisticRegression(C=10),
    ),
}
```

## Code Concatenation
```python
classifiers = {
    "Logistic regression\n(C=0.01)": LogisticRegression(C=0.1),
    "Logistic regression\n(C=1)": LogisticRegression(C=100),
    "Gaussian Process": GaussianProcessClassifier(kernel=1.0 * RBF([1.0, 1.0])),
    "Logistic regression\n(RBF features)": make_pipeline(
        Nystroem(kernel="rbf", gamma=5e-1, n_components=50, random_state=1),
        LogisticRegression(C=10),
    ),
    "Gradient Boosting": HistGradientBoostingClassifier(),
    "Logistic regression\n(binned features)": make_pipeline(
        KBinsDiscretizer(n_bins=5, quantile_method="averaged_inverted_cdf"),
        PolynomialFeatures(interaction_only=True),
        LogisticRegression(C=10),
    ),
    "Logistic regression\n(spline features)": make_pipeline(
        SplineTransformer(n_knots=5),
        PolynomialFeatures(interaction_only=True),
        LogisticRegression(C=10),
    ),
}
```
