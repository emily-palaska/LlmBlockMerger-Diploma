{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "def laplacian_parameters(G, symm):",
   "id": "7e87afc2be05b552"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate asymmetric Laplacian normalization\n",
    "degv = {v : float(len(list(G.neighbors(v))))**symm for v in G.nodes()}\n",
    "degu = {u : float(len(list(G.neighbors(u))))**(1-symm) for u in G.nodes()}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def visualize(G, p):",
   "id": "ec60ecdfe9839ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# normalize priors\n",
    "p_sum = sum(p.values())\n",
    "normalized_prior_ranks = {u: p[u]/p_sum for u in p}\n",
    "#\n",
    "print('----- Visualizing using d3 -----')\n",
    "data = {}\n",
    "data['nodes'] = [{'id':str(u),'color_intensity':normalized_prior_ranks[u]} for u in G.nodes()]\n",
    "data['links'] = [{'source':str(node1),'target':str(node2),'value':1} for node1,node2 in G.edges()]\n",
    "import os, json\n",
    "with open('visualize/data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "os.system('start firefox.exe \"file:///'+os.getcwd()+'/visualize/visualize.html\"')"
   ],
   "id": "2918825e221d1263"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def pagerank(G, prior_ranks, a, msq_error):",
   "id": "dcd4e40ea323b6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# calculate normalization parameters of symmetric Laplacian\n",
    "degv = {v : float(len(list(G.neighbors(v))))**0.5 for v in G.nodes()}\n",
    "degu = {u : float(len(list(G.neighbors(u))))**0.5 for u in G.nodes()}\n",
    "# iterate to calculate PageRank\n",
    "ranks = prior_ranks\n",
    "while True:\n",
    "    msq = 0\n",
    "    next_ranks = {}\n",
    "    for u in G.nodes():\n",
    "        rank = sum(ranks[v]/degv[v]/degu[u] for v in G.neighbors(u))\n",
    "        next_ranks[u] = rank*a + prior_ranks[u]*(1-a)\n",
    "        msq += (next_ranks[u]-ranks[u])**2\n",
    "    ranks = next_ranks\n",
    "    if msq/len(G.nodes())<msq_error:\n",
    "        break"
   ],
   "id": "5bf6345a832bea75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def pagerank_fast(G, prior_ranks, a, msq_error, order):",
   "id": "78577ede4d8e185e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# calculate normalization parameters of symmetric Laplacian\n",
    "degv = {v : float(len(list(G.neighbors(v))))**0.5 for v in G.nodes()}\n",
    "degu = {u : float(len(list(G.neighbors(u))))**0.5 for u in G.nodes()}\n",
    "# iterate to calculate PageRank using quotient\n",
    "ranks = prior_ranks\n",
    "while True:\n",
    "    msq = 0\n",
    "    next_ranks = {}\n",
    "    for u in G.nodes():\n",
    "        rank = sum(ranks[v]/degv[v]/degu[u] for v in G.neighbors(u))\n",
    "        next_ranks[u] = rank*a + prior_ranks[u]*(1-a)\n",
    "        msq += (next_ranks[u]-ranks[u])**2\n",
    "    ranks = next_ranks / np.norm(next_ranks.sum(), order)\n",
    "    if msq/len(G.nodes())<msq_error:\n",
    "        break"
   ],
   "id": "f639c8295ca1a113"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def train_lr(x_train, y_train, preprocessing=\"normalize\"):",
   "id": "b54e8983ee49412"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "# select preprocessing method\n",
    "if preprocessing == \"normalize\":\n",
    "    # Normalize training data\n",
    "    x_train = (x_train - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))\n",
    "elif preprocessing == \"standardize\":\n",
    "    # Standardize training data\n",
    "    x_train = (x_train - x_train.mean(axis=0)) / (x_train.std(axis=0))\n",
    "# train\n",
    "model.train(x_train, y_train)"
   ],
   "id": "84bec73be5d35bd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def test(x_train, y_train, x_test, y_test):",
   "id": "a959f678f1e3ba6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = LogisticRegression()\n",
    "model.train(x_train, y_train)\n",
    "# Evaluate using test data\n",
    "y_hat = model.predict(x_test, probs=True)"
   ],
   "id": "e3d09bf41655e152"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def createSVR(x, y):",
   "id": "1f06bb2c261f7460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "svr = SVR()\n",
    "svr.train(x, y)"
   ],
   "id": "77246f5695fc1be1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "def load_custom_model(path, CustomClassifier, x, y):",
   "id": "791684ec8de5307d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if os.path.isfile(path):\n",
    "    custom = pickle.load(path)\n",
    "else:\n",
    "    custom = CustomClassifier()\n",
    "    custom.train(x, y)\n",
    "    # save\n",
    "    pickle.dump(custom, path)"
   ],
   "id": "75a7e3e8bae80cbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
